{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入依赖库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, vmap, random\n",
    "import interpax\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_read_dat(dat_name):\n",
    "    \"\"\"\n",
    "    安全读取数据文件，返回numpy数组。\n",
    "    \"\"\"\n",
    "    path = os.path.join('./data', dat_name)\n",
    "    try:\n",
    "        data = np.loadtxt(path)\n",
    "        return data\n",
    "    except OSError:\n",
    "        print(f\"Cannot find file {path} in current directory\")\n",
    "        return np.array([])\n",
    "\n",
    "\n",
    "ALPHA1 = safe_read_dat(r'ALPHA1.dat')\n",
    "BETA1 = safe_read_dat(r'BETA1.dat')\n",
    "DH1 = safe_read_dat(r'DH1.dat')\n",
    "Cx = safe_read_dat(r'CX0120_ALPHA1_BETA1_DH1_201.dat')\n",
    "Cz = safe_read_dat(r'CZ0120_ALPHA1_BETA1_DH1_301.dat')\n",
    "Cm = safe_read_dat(r'CM0120_ALPHA1_BETA1_DH1_101.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy版本插值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trilinear_interp_numpy(grid_x, grid_y, grid_z, values, points):\n",
    "    \"\"\"\n",
    "    三维线性插值函数\n",
    "\n",
    "    参数:\n",
    "    - grid_x, grid_y, grid_z: 三个维度的网格坐标（升序排列），形状分别为 (nx,), (ny,), (nz,)\n",
    "    - values: 网格点的值，形状为 (nx, ny, nz)\n",
    "    - points: 插值点的坐标，形状为 (num_points, 3)\n",
    "\n",
    "    返回:\n",
    "    - 插值后的值，形状为 (num_points,)\n",
    "    \"\"\"\n",
    "    x, y, z = points[:, 0], points[:, 1], points[:, 2]\n",
    "    # 找到每个插值点所在的索引\n",
    "    ix = np.searchsorted(grid_x, x) - 1\n",
    "    iy = np.searchsorted(grid_y, y) - 1\n",
    "    iz = np.searchsorted(grid_z, z) - 1\n",
    "\n",
    "    # 确保索引在有效范围内\n",
    "    ix = np.clip(ix, 0, len(grid_x) - 2)\n",
    "    iy = np.clip(iy, 0, len(grid_y) - 2)\n",
    "    iz = np.clip(iz, 0, len(grid_z) - 2)\n",
    "\n",
    "    # 获取立方体的八个顶点的值\n",
    "    c000 = values[ix    , iy    , iz    ]\n",
    "    c100 = values[ix + 1, iy    , iz    ]\n",
    "    c010 = values[ix    , iy + 1, iz    ]\n",
    "    c110 = values[ix + 1, iy + 1, iz    ]\n",
    "    c001 = values[ix    , iy    , iz + 1]\n",
    "    c101 = values[ix + 1, iy    , iz + 1]\n",
    "    c011 = values[ix    , iy + 1, iz + 1]\n",
    "    c111 = values[ix + 1, iy + 1, iz + 1]\n",
    "\n",
    "    # 计算插值权重\n",
    "    x0 = grid_x[ix]\n",
    "    x1 = grid_x[ix + 1]\n",
    "    y0 = grid_y[iy]\n",
    "    y1 = grid_y[iy + 1]\n",
    "    z0 = grid_z[iz]\n",
    "    z1 = grid_z[iz + 1]\n",
    "\n",
    "    xd = (x - x0) / (x1 - x0)\n",
    "    yd = (y - y0) / (y1 - y0)\n",
    "    zd = (z - z0) / (z1 - z0)\n",
    "\n",
    "    # 插值\n",
    "    c00 = c000 * (1 - xd) + c100 * xd\n",
    "    c01 = c001 * (1 - xd) + c101 * xd\n",
    "    c10 = c010 * (1 - xd) + c110 * xd\n",
    "    c11 = c011 * (1 - xd) + c111 * xd\n",
    "\n",
    "    c0 = c00 * (1 - yd) + c10 * yd\n",
    "    c1 = c01 * (1 - yd) + c11 * yd\n",
    "\n",
    "    c = c0 * (1 - zd) + c1 * zd\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09211591,  0.06790906,  0.07973837,  0.09735869,  0.06644634,\n",
       "        0.02940378, -0.00740422,  0.03257879,  0.07910723,  0.10494726])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALPHA1_numpy = np.array(ALPHA1)\n",
    "BETA1_numpy = np.array(BETA1)\n",
    "DH1_numpy = np.array(DH1)\n",
    "CX_numpy = np.array(Cx)\n",
    "CX_numpy = CX_numpy.reshape((DH1_numpy.shape[0], BETA1_numpy.shape[0], ALPHA1_numpy.shape[0]))\n",
    "\n",
    "n = 10\n",
    "alpha, beta, el = 90, 30, 25\n",
    "np.random.seed(42)\n",
    "alpha_lst= alpha * np.random.uniform(0, 1, (n, 1))\n",
    "beta_lst = beta * np.random.uniform(0, 1, (n, 1))\n",
    "el_lst = el * np.random.uniform(0, 1, (n, 1))\n",
    "input_points = np.hstack((el_lst, beta_lst, alpha_lst))\n",
    "trilinear_interp_numpy(DH1_numpy, BETA1_numpy, ALPHA1_numpy, CX_numpy, input_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.9 μs ± 1.21 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit trilinear_interp_numpy(DH1_numpy, BETA1_numpy, ALPHA1_numpy, CX_numpy, input_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch版本插值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trilinear_interp_tensor(grid_x, grid_y, grid_z, values, points):\n",
    "    \"\"\"\n",
    "    三维线性插值函数\n",
    "\n",
    "    参数:\n",
    "    - grid_x, grid_y, grid_z: 三个维度的网格坐标（升序排列），形状分别为 (nx,), (ny,), (nz,)\n",
    "    - values: 网格点的值，形状为 (nx, ny, nz)\n",
    "    - points: 插值点的坐标，形状为 (num_points, 3)\n",
    "\n",
    "    返回:\n",
    "    - 插值后的值，形状为 (num_points,)\n",
    "    \"\"\"\n",
    "    x, y, z = points[:, 0].contiguous(), points[:, 1].contiguous(), points[:, 2].contiguous()\n",
    "    # 找到每个插值点所在的索引\n",
    "    ix = torch.searchsorted(grid_x, x) - 1\n",
    "    iy = torch.searchsorted(grid_y, y) - 1\n",
    "    iz = torch.searchsorted(grid_z, z) - 1\n",
    "\n",
    "    # 确保索引在有效范围内\n",
    "    ix = torch.clip(ix, 0, len(grid_x) - 2)\n",
    "    iy = torch.clip(iy, 0, len(grid_y) - 2)\n",
    "    iz = torch.clip(iz, 0, len(grid_z) - 2)\n",
    "\n",
    "    # 获取立方体的八个顶点的值\n",
    "    c000 = values[ix    , iy    , iz    ]\n",
    "    c100 = values[ix + 1, iy    , iz    ]\n",
    "    c010 = values[ix    , iy + 1, iz    ]\n",
    "    c110 = values[ix + 1, iy + 1, iz    ]\n",
    "    c001 = values[ix    , iy    , iz + 1]\n",
    "    c101 = values[ix + 1, iy    , iz + 1]\n",
    "    c011 = values[ix    , iy + 1, iz + 1]\n",
    "    c111 = values[ix + 1, iy + 1, iz + 1]\n",
    "\n",
    "    # 计算插值权重\n",
    "    x0 = grid_x[ix]\n",
    "    x1 = grid_x[ix + 1]\n",
    "    y0 = grid_y[iy]\n",
    "    y1 = grid_y[iy + 1]\n",
    "    z0 = grid_z[iz]\n",
    "    z1 = grid_z[iz + 1]\n",
    "\n",
    "    xd = (x - x0) / (x1 - x0)\n",
    "    yd = (y - y0) / (y1 - y0)\n",
    "    zd = (z - z0) / (z1 - z0)\n",
    "\n",
    "    # 插值\n",
    "    c00 = c000 * (1 - xd) + c100 * xd\n",
    "    c01 = c001 * (1 - xd) + c101 * xd\n",
    "    c10 = c010 * (1 - xd) + c110 * xd\n",
    "    c11 = c011 * (1 - xd) + c111 * xd\n",
    "\n",
    "    c0 = c00 * (1 - yd) + c10 * yd\n",
    "    c1 = c01 * (1 - yd) + c11 * yd\n",
    "\n",
    "    c = c0 * (1 - zd) + c1 * zd\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0566,  0.0357,  0.0807, -0.0085,  0.1090,  0.0999,  0.0963,  0.0738,\n",
       "         0.0362,  0.0652], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALPHA1_tensor = torch.tensor(ALPHA1, device=device)\n",
    "BETA1_tensor = torch.tensor(BETA1, device=device)\n",
    "DH1_tensor = torch.tensor(DH1, device=device)\n",
    "CX_tensor = torch.tensor(Cx, device=device)\n",
    "CX_tensor = CX_tensor.reshape((DH1_tensor.shape[0], BETA1_tensor.shape[0], ALPHA1_tensor.shape[0]))\n",
    "\n",
    "n = 10\n",
    "alpha, beta, el = 90, 30, 25\n",
    "torch.manual_seed(42)\n",
    "alpha_lst= alpha * torch.rand((n, 1), device=device)\n",
    "beta_lst = beta * torch.rand((n, 1), device=device)\n",
    "el_lst = el * torch.rand((n, 1), device=device)\n",
    "input_points = torch.hstack((el_lst, beta_lst, alpha_lst))\n",
    "trilinear_interp_tensor(DH1_tensor, BETA1_tensor, ALPHA1_tensor, CX_tensor, input_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270 μs ± 18.4 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit trilinear_interp_tensor(DH1_tensor, BETA1_tensor, ALPHA1_tensor, CX_tensor, input_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, hidden_list):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        lastv = in_dim\n",
    "        for hidden in hidden_list:\n",
    "            layers.append(nn.Linear(lastv, hidden))\n",
    "            layers.append(nn.ReLU())\n",
    "            lastv = hidden\n",
    "        layers.append(nn.Linear(lastv, out_dim))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float32)\n",
    "        ret = self.layers(x)\n",
    "        ret = ret.reshape(-1)\n",
    "        return ret\n",
    "    \n",
    "\n",
    "def normalize(X, mean, std):\n",
    "    return (X - mean) / std\n",
    "\n",
    "\n",
    "def unnormalize(X, mean, std):\n",
    "    return X * std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xcy\\AppData\\Local\\Temp\\ipykernel_24212\\4152871600.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Cx_model.load_state_dict(torch.load('./model/Cx.pth', map_location=device))\n",
      "C:\\Users\\xcy\\AppData\\Local\\Temp\\ipykernel_24212\\4152871600.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Cz_model.load_state_dict(torch.load('./model/Cz.pth', map_location=device))\n",
      "C:\\Users\\xcy\\AppData\\Local\\Temp\\ipykernel_24212\\4152871600.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Cm_model.load_state_dict(torch.load('./model/Cm.pth', map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./model/mean_std.csv')\n",
    "Cx_model = MLP(3, 1, [20, 10]).to(device=device)\n",
    "Cx_model.load_state_dict(torch.load('./model/Cx.pth', map_location=device))\n",
    "Cz_model = MLP(3, 1, [20, 10]).to(device=device)\n",
    "Cz_model.load_state_dict(torch.load('./model/Cz.pth', map_location=device))\n",
    "Cm_model = MLP(3, 1, [20, 10]).to(device=device)\n",
    "Cm_model.load_state_dict(torch.load('./model/Cm.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def _Cx(alpha, beta, dele):\n",
    "    name = data['name']\n",
    "    index = list(name).index('Cx')\n",
    "    alpha_mean = data['alpha_mean'][index]\n",
    "    alpha_std = data['alpha_std'][index]\n",
    "    alpha = normalize(alpha, alpha_mean, alpha_std)\n",
    "    beta_mean = data['beta_mean'][index]\n",
    "    beta_std = data['beta_std'][index]\n",
    "    beta = normalize(beta, beta_mean, beta_std)\n",
    "    el_mean = data['el_mean'][index]\n",
    "    el_std = data['el_std'][index]\n",
    "    dele = normalize(dele, el_mean, el_std)\n",
    "    input = torch.hstack((alpha.reshape(-1, 1), beta.reshape(-1, 1)))\n",
    "    input = torch.hstack((input, dele.reshape(-1, 1)))\n",
    "    mean = data['mean'][index]\n",
    "    std = data['std'][index]\n",
    "    return unnormalize(Cx_model.forward(input), mean, std)\n",
    "\n",
    "@torch.no_grad()\n",
    "def _Cz(alpha, beta, dele):\n",
    "    name = data['name']\n",
    "    index = list(name).index('Cz')\n",
    "    alpha_mean = data['alpha_mean'][index]\n",
    "    alpha_std = data['alpha_std'][index]\n",
    "    alpha = normalize(alpha, alpha_mean, alpha_std)\n",
    "    beta_mean = data['beta_mean'][index]\n",
    "    beta_std = data['beta_std'][index]\n",
    "    beta = normalize(beta, beta_mean, beta_std)\n",
    "    el_mean = data['el_mean'][index]\n",
    "    el_std = data['el_std'][index]\n",
    "    dele = normalize(dele, el_mean, el_std)\n",
    "    input = torch.hstack((alpha.reshape(-1, 1), beta.reshape(-1, 1)))\n",
    "    input = torch.hstack((input, dele.reshape(-1, 1)))\n",
    "    mean = data['mean'][index]\n",
    "    std = data['std'][index]\n",
    "    return unnormalize(Cz_model.forward(input), mean, std)\n",
    "\n",
    "@torch.no_grad()\n",
    "def _Cm(alpha, beta, dele):\n",
    "    name = data['name']\n",
    "    index = list(name).index('Cm')\n",
    "    alpha_mean = data['alpha_mean'][index]\n",
    "    alpha_std = data['alpha_std'][index]\n",
    "    alpha = normalize(alpha, alpha_mean, alpha_std)\n",
    "    beta_mean = data['beta_mean'][index]\n",
    "    beta_std = data['beta_std'][index]\n",
    "    beta = normalize(beta, beta_mean, beta_std)\n",
    "    el_mean = data['el_mean'][index]\n",
    "    el_std = data['el_std'][index]\n",
    "    dele = normalize(dele, el_mean, el_std)\n",
    "    input = torch.hstack((alpha.reshape(-1, 1), beta.reshape(-1, 1)))\n",
    "    input = torch.hstack((input, dele.reshape(-1, 1)))\n",
    "    mean = data['mean'][index]\n",
    "    std = data['std'][index]\n",
    "    return unnormalize(Cm_model.forward(input), mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0569,  0.0363,  0.0922, -0.0021,  0.1106,  0.0975,  0.0899,  0.0771,\n",
       "         0.0347,  0.0606])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "alpha, beta, el = 90, 30, 25\n",
    "torch.manual_seed(42)\n",
    "alpha_lst= alpha * torch.rand((n, 1), device=device)\n",
    "beta_lst = beta * torch.rand((n, 1), device=device)\n",
    "el_lst = el * torch.rand((n, 1), device=device)\n",
    "_Cx(alpha_lst, beta_lst, el_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 μs ± 806 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _Cx(alpha_lst, beta_lst, el_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JAX版本插值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def trilinear_interp_jax(grid_x, grid_y, grid_z, values, points):\n",
    "    \"\"\"\n",
    "    三维线性插值函数\n",
    "\n",
    "    参数:\n",
    "    - grid_x, grid_y, grid_z: 三个维度的网格坐标（升序排列），形状分别为 (nx,), (ny,), (nz,)\n",
    "    - values: 网格点的值，形状为 (nx, ny, nz)\n",
    "    - points: 插值点的坐标，形状为 (num_points, 3)\n",
    "\n",
    "    返回:\n",
    "    - 插值后的值，形状为 (num_points,)\n",
    "    \"\"\"\n",
    "    def single_interp(point):\n",
    "        x, y, z = point\n",
    "        # 找到每个插值点所在的索引\n",
    "        ix = jnp.searchsorted(grid_x, x) - 1\n",
    "        iy = jnp.searchsorted(grid_y, y) - 1\n",
    "        iz = jnp.searchsorted(grid_z, z) - 1\n",
    "\n",
    "        # 确保索引在有效范围内\n",
    "        ix = jnp.clip(ix, 0, len(grid_x) - 2)\n",
    "        iy = jnp.clip(iy, 0, len(grid_y) - 2)\n",
    "        iz = jnp.clip(iz, 0, len(grid_z) - 2)\n",
    "\n",
    "        # 获取立方体的八个顶点的值\n",
    "        c000 = values[ix    , iy    , iz    ]\n",
    "        c100 = values[ix + 1, iy    , iz    ]\n",
    "        c010 = values[ix    , iy + 1, iz    ]\n",
    "        c110 = values[ix + 1, iy + 1, iz    ]\n",
    "        c001 = values[ix    , iy    , iz + 1]\n",
    "        c101 = values[ix + 1, iy    , iz + 1]\n",
    "        c011 = values[ix    , iy + 1, iz + 1]\n",
    "        c111 = values[ix + 1, iy + 1, iz + 1]\n",
    "\n",
    "        # 计算插值权重\n",
    "        x0 = grid_x[ix]\n",
    "        x1 = grid_x[ix + 1]\n",
    "        y0 = grid_y[iy]\n",
    "        y1 = grid_y[iy + 1]\n",
    "        z0 = grid_z[iz]\n",
    "        z1 = grid_z[iz + 1]\n",
    "\n",
    "        xd = (x - x0) / (x1 - x0)\n",
    "        yd = (y - y0) / (y1 - y0)\n",
    "        zd = (z - z0) / (z1 - z0)\n",
    "\n",
    "        # 插值\n",
    "        c00 = c000 * (1 - xd) + c100 * xd\n",
    "        c01 = c001 * (1 - xd) + c101 * xd\n",
    "        c10 = c010 * (1 - xd) + c110 * xd\n",
    "        c11 = c011 * (1 - xd) + c111 * xd\n",
    "\n",
    "        c0 = c00 * (1 - yd) + c10 * yd\n",
    "        c1 = c01 * (1 - yd) + c11 * yd\n",
    "\n",
    "        c = c0 * (1 - zd) + c1 * zd\n",
    "\n",
    "        return c\n",
    "\n",
    "    # 使用 vmap 对每个插值点应用插值函数\n",
    "    interpolated = vmap(single_interp)(points)\n",
    "    return interpolated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 0.01771834,  0.09925664,  0.10315857,  0.05268927,  0.06349808,\n",
       "        0.04405698, -0.07633661,  0.05153302,  0.05967385,  0.04271419],      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALPHA1_jnp = jnp.array(ALPHA1)\n",
    "BETA1_jnp = jnp.array(BETA1)\n",
    "DH1_jnp = jnp.array(DH1)\n",
    "CX_jnp = jnp.array(Cx)\n",
    "CX_jnp = CX_jnp.reshape((DH1_jnp.shape[0], BETA1_jnp.shape[0], ALPHA1_jnp.shape[0]))\n",
    "\n",
    "n = 10\n",
    "alpha, beta, el = 90, 30, 25\n",
    "\n",
    "key = random.PRNGKey(42)\n",
    "alpha_key, beta_key, el_key = random.split(key, 3)\n",
    "alpha_lst = alpha * random.uniform(alpha_key, (n, 1))\n",
    "beta_lst = beta * random.uniform(beta_key, (n, 1))\n",
    "el_lst = el * random.uniform(el_key, (n, 1))\n",
    "input_points = jnp.hstack((el_lst, beta_lst, alpha_lst))\n",
    "\n",
    "trilinear_interp_jax(DH1_jnp, BETA1_jnp, ALPHA1_jnp, CX_jnp, input_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.79 μs ± 211 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit trilinear_interp_jax(DH1_jnp, BETA1_jnp, ALPHA1_jnp, CX_jnp, input_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## interpax版本插值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def trilinear_interpax(grid_x, grid_y, grid_z, values, points):\n",
    "    \"\"\"\n",
    "    三维线性插值函数\n",
    "\n",
    "    参数:\n",
    "    - grid_x, grid_y, grid_z: 三个维度的网格坐标（升序排列），形状分别为 (nx,), (ny,), (nz,)\n",
    "    - values: 网格点的值，形状为 (nx, ny, nz)\n",
    "    - points: 插值点的坐标，形状为 (num_points, 3)\n",
    "\n",
    "    返回:\n",
    "    - 插值后的值，形状为 (num_points,)\n",
    "    \"\"\"\n",
    "    interplot3d = interpax.Interpolator3D(grid_x, grid_y, grid_z, values)\n",
    "\n",
    "    def single_interp(point):\n",
    "        x, y, z = point\n",
    "        return interplot3d(x, y, z)\n",
    "\n",
    "    # 使用 vmap 对每个插值点应用插值函数\n",
    "    interpolated = vmap(single_interp)(points)\n",
    "    return interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 0.01740061,  0.09906071,  0.10461072,  0.05284601,  0.0621539 ,\n",
       "        0.04622418, -0.07554753,  0.05037436,  0.06079885,  0.04157751],      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALPHA1_jnp = jnp.array(ALPHA1)\n",
    "BETA1_jnp = jnp.array(BETA1)\n",
    "DH1_jnp = jnp.array(DH1)\n",
    "CX_jnp = jnp.array(Cx)\n",
    "CX_jnp = CX_jnp.reshape((DH1_jnp.shape[0], BETA1_jnp.shape[0], ALPHA1_jnp.shape[0]))\n",
    "\n",
    "n = 10\n",
    "alpha, beta, el = 90, 30, 25\n",
    "\n",
    "key = random.PRNGKey(42)\n",
    "alpha_key, beta_key, el_key = random.split(key, 3)\n",
    "alpha_lst = alpha * random.uniform(alpha_key, (n, 1))\n",
    "beta_lst = beta * random.uniform(beta_key, (n, 1))\n",
    "el_lst = el * random.uniform(el_key, (n, 1))\n",
    "input_points = jnp.hstack((el_lst, beta_lst, alpha_lst))\n",
    "\n",
    "trilinear_interpax(DH1_jnp, BETA1_jnp, ALPHA1_jnp, CX_jnp, input_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.3 μs ± 1.25 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit trilinear_interpax(DH1_jnp, BETA1_jnp, ALPHA1_jnp, CX_jnp, input_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试时间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.5 μs ± 2.46 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "76.1 μs ± 2.08 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "167 μs ± 1.16 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "1.33 ms ± 4.37 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "21.9 ms ± 438 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "269 ms ± 15.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "ns = [10, 100, 1000, 10000, 100000, 1000000]\n",
    "\n",
    "for n in ns:\n",
    "    alpha, beta, el = 90, 30, 25\n",
    "    alpha_lst= alpha * np.random.uniform(0, 1, (n, 1))\n",
    "    beta_lst = beta * np.random.uniform(0, 1, (n, 1))\n",
    "    el_lst = el * np.random.uniform(0, 1, (n, 1))\n",
    "    input_points = np.hstack((el_lst, beta_lst, alpha_lst))\n",
    "    %timeit trilinear_interp_numpy(DH1_numpy, BETA1_numpy, ALPHA1_numpy, CX_numpy, input_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288 μs ± 10.7 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "282 μs ± 2.44 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "467 μs ± 6.43 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "1.25 ms ± 64.5 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "7.05 ms ± 387 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "55.5 ms ± 2.48 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "ns = [10, 100, 1000, 10000, 100000, 1000000]\n",
    "\n",
    "for n in ns:\n",
    "    alpha, beta, el = 90, 30, 25\n",
    "    alpha_lst= alpha * torch.rand((n, 1), device=device)\n",
    "    beta_lst = beta * torch.rand((n, 1), device=device)\n",
    "    el_lst = el * torch.rand((n, 1), device=device)\n",
    "    input_points = torch.hstack((el_lst, beta_lst, alpha_lst))\n",
    "    %timeit trilinear_interp_tensor(DH1_tensor, BETA1_tensor, ALPHA1_tensor, CX_tensor, input_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 μs ± 2.57 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "149 μs ± 4.75 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "218 μs ± 3.88 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "552 μs ± 6.19 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "2.72 ms ± 178 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "26.6 ms ± 134 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "ns = [10, 100, 1000, 10000, 100000, 1000000]\n",
    "for n in ns:\n",
    "    alpha, beta, el = 90, 30, 25\n",
    "    alpha_lst= alpha * torch.rand((n, 1), device=device)\n",
    "    beta_lst = beta * torch.rand((n, 1), device=device)\n",
    "    el_lst = el * torch.rand((n, 1), device=device)\n",
    "    %timeit _Cx(alpha_lst, beta_lst, el_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jax版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.45 μs ± 270 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "9.82 μs ± 460 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "48.8 μs ± 2.72 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "303 μs ± 18.3 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "The slowest run took 10.85 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "22.4 μs ± 26.5 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "33.6 ms ± 1.13 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "ns = [10, 100, 1000, 10000, 100000, 1000000]\n",
    "# ns = [1000000]\n",
    "for n in ns:\n",
    "    alpha, beta, el = 90, 30, 25\n",
    "\n",
    "    key = random.PRNGKey(42)\n",
    "    alpha_key, beta_key, el_key = random.split(key, 3)\n",
    "    alpha_lst = alpha * random.uniform(alpha_key, (n, 1))\n",
    "    beta_lst = beta * random.uniform(beta_key, (n, 1))\n",
    "    el_lst = el * random.uniform(el_key, (n, 1))\n",
    "    input_points = jnp.hstack((el_lst, beta_lst, alpha_lst))\n",
    "\n",
    "    %timeit trilinear_interp_jax(DH1_jnp, BETA1_jnp, ALPHA1_jnp, CX_jnp, input_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### interpax版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.7 μs ± 2.23 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "The slowest run took 6.15 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "34.7 μs ± 31.4 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "The slowest run took 8.27 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "24.8 μs ± 28.7 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "The slowest run took 11.81 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "27.9 μs ± 37.8 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "The slowest run took 10.54 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "59 μs ± 62.1 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "The slowest run took 11.55 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "25.3 μs ± 30.4 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "ns = [10, 100, 1000, 10000, 100000, 1000000]\n",
    "for n in ns:\n",
    "    alpha, beta, el = 90, 30, 25\n",
    "\n",
    "    key = random.PRNGKey(42)\n",
    "    alpha_key, beta_key, el_key = random.split(key, 3)\n",
    "    alpha_lst = alpha * random.uniform(alpha_key, (n, 1))\n",
    "    beta_lst = beta * random.uniform(beta_key, (n, 1))\n",
    "    el_lst = el * random.uniform(el_key, (n, 1))\n",
    "    input_points = jnp.hstack((el_lst, beta_lst, alpha_lst))\n",
    "\n",
    "    %timeit trilinear_interpax(DH1_jnp, BETA1_jnp, ALPHA1_jnp, CX_jnp, input_points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeroplanax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
